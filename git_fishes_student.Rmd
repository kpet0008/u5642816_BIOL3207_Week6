---
title: "Git, GitHub & Ocean Acidification"
author: "Kalon Peters, u5642816"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    code_folding: show
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=2)
```

# **Introduction**

This tutorial will draw on the skills you have already learnt on data visualisation, data wrangling and NHST to analyse a data set on ocean acidification effects on fish behaviour. However, we'll do that in the context of some new workflows that adopt Git and GitHub. 

Use this Rmarkdown file as your template to complete the tasks outlined within the instructions. There are questions asked in the instructions and here in the RMarkdown file. Answer these as best as you can to document your steps and thinking. There are also a series of coding exercises. 

Throughout we are also going to learn a bit more about how to format Rmarkdown documents. So, pay close attention to the formatting. We're also going to make use of the `bookdown` package now to render your Rmarkdown because, well, it's quite elegant in many ways. Before you start the tasks install the following packages:

```{r loadpacks, message=FALSE, results='hide'}
# Install a load of packages that we'll use. I'll show you a shortcut that I love to use. Try using the p_load function in the "pacman" package. p_load will execute both the install.packages and library commands in one shot so they only need to be used once to install pacman itself.
#install.packages("pacman", repos = "http://cran.us.r-project.org")
library(pacman)

# Install bookdown for rendering because we'll need this. While we're at it, lets also install /load the tidyverse
## Im not running this every time
#p_load(bookdown, tidyverse, ggforce, flextable, latex2exp, png, magick) # basically just list all the packages you want here

library(bookdown)
library(tidyverse)
library(ggforce)
library(flextable)
library(latex2exp)
library(png)
library(magick)

```

# **Task 1**

### Provide the link to your GitHub Repo 

While the tasks are meant to get you familiar with how *GitHub* works you should try and make regular commits as you work your way through. We want to see how often you're using *Git*. Below, within the `()` brackets provide the link to your GitHub Repo. Just cut and paste it so we know what the repo name is and where it is. 

[My GitHub Repository](https://github.com/kpet0008/u5642816_BIOL3207_Week6)

By adding the link in the `()` brackets it will hyperlink "My GitHub Repository". This is how to hyperlink in Rmarkdown documents.


# **Task 2**

This task involves cloning your repository on your computer. Where should we place this repository? While GitHub is somewhat of a cloud storage system because it's keeping record of your commits, files and changes in the cloud it is **not** a backup of your files (note that placing `**` around a word will bold it whereas `*` around a word will italicise it). The lack of *GitHub* being a file backup system is important to recognise! 

>**Question 1**: Why should you not rely on *GitHub* as a backup?

```{r, answer1, echo=TRUE, eval = FALSE}

## I really cannot find an answer to this question that amounts to anything more than "because I said so". Its always seemed perfectly capable as a backup in my experience with it.

```

I'd usually suggest placing your repo in a cloud storage system like, *OneDrive*, *Dropbox*, or *GoogleDrive*. These will ensure that all your files are backed up and *GitHub* will provide a record of the detailed history. 

Before moving on you might have noticed that the code block above has a name `answer1` and I've added an argument `echo = TRUE`. It's good to label code blocks with useful names to help you debug when rendering of your document goes wrong (when, not IF!). These names need to all be unique. There are a whole bunch of arguments that you can list within code chunks that tell each chunk what to do. You can look to the great [Rmarkdown cheetsheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) for more information.

>**Question 2**: In the second code block called `answer1` if we change echo = TRUE to echo = FALSE what will happen to the code block `answer1` when you render it?

```{r answer2, echo=TRUE, eval = FALSE}
# The code block will not be visible in the rendered document
```


**Important**: Notice that `eval = FALSE` for many code chunks. When you complete the tasks. Make sure to change these to `TRUE` otherwise you will find your code does not run!

# **Task 3**

Hopefully you have now successfully cloned down your *GitHub* repo. This is your new working directory from which your project will develop. 

Hopefully you also created and/or downloaded the following files and added them to your cloned repo:

1) created a new RStudio project file in your working directory
2) download the `OA_activitydat_20190302_BIOL3207.csv` from Wattle and add this to a `data/` folder in your repo 
3) Add the template Rmarkdown file, `git_fishes_student.Rmd` that was provided on wattle. You'll use this file to work through the tasks and answer questions. 

**STOP**: Before moving on, it's a good time to establish some good *GitHub* practices. You have just did an important step -- you added a bunch of new files. It's time stage these files and commit them so that you have a record. Use *GitHub Desktop* to do this. 

This is also a very good point to make sure that you understand relative path names fo coding. Wait, "relative what?". Your working directory can be considered the 'lowest' level of your project. The starting point, if you will. R needs to know where your files are that you want to load. Many people might be familiar with using the `setwd()` function to tell R where your files are that you need to load. This is problematic because everyone's path to a given working directory is different, and so, your code will not work on others' computers. Even across your own computers!

Lucky, RStudio project files take away the main issue by creating a project file that allows anyone to click on it to open the working directory to the same "spot". Having said that, if you start building structure (i.e., folders) in your working directory or repo than you need to understand how to navigate between folders to load and write files in the places that you want. 

Make sure you have added a `data/` folder to your working directory that you just cloned down. Think about how you would write some code to load in a data file that is within this folder. There are a few useful shortcuts you can use. For example, if you use `.` it means 'start from the current working directory'. That is the RStudio project file location if you click on a RStudio project. If you use `..` it means "start from the directory or folder one step back from the existing working directory".

>**Question 3**: **How would you write the path name to load in a data file from the data folder?**

Write your answer in the code chunk below:

```{r, loaddata, eval = TRUE, echo=TRUE}

path <- "./data/OA_activitydat_20190302_BIOL3207.csv"
  
data <- read_csv(path)

```

Let's say that you added a new data folder that was inside an output folder (i.e., `output/data`) to your working directory. The purpose of this folder is to store and track your cleaned up data frame after you have done all your data wrangling and corrections. 

>**Question 4**: Using the `write_csv` function how would you write the path name to save this file to `output/data`?

```{r, write, eval = TRUE, echo=TRUE}
#why is this question here and not *after* the data has been cleaned?

path <- "./output/data/OA_activitydat_20190302_BIOL3207_output.csv"

write_csv(data, file = path)

```


# **Task 4**

We're ready for some coding! Lets do some coding and wrangling of the `OA_activitydat_20190302_BIOL3207.csv` data that we will use for the workshop. Note above, the `loaddata` code chunk should have already written the code to load the data file. At this point, we're assuming it's in your working space. If not, make sure you run the `loaddata` code chunk. 

First, write some code below to remove missing data

```{r, rmMiss}
# Code to removing missing data from the `OA_activitydat_20190302_BIOL3207.csv` data frame. 
data_cleaning <- filter(data, !is.na(activity))
data_cleaning <- filter(data_cleaning, !is.na(animal_id)) %>% mutate(across(where(is.character), factor))
```

Second, drop out irrelevant columns and check that there are no spelling issues in `species` and `treatment`. Create a table of summary data that includes: 1) the mean, 2) the standard error and 3) the sample sizes of unique fish across ALL six fish species for each treatment. This will also help you detect any spelling errors. You can use the R package [`flextable`](https://ardata-fr.github.io/flextable-book/) to print out the results in a nice neat format! If you haven't heard about `flextable` spend 10 or so minutes having a look at it's functionality. It's incredible! You'll use this for tables throughout.

```{r summaryTab}
# Drop irrelevant columns, which is most of them
# Only keeping species, treatment, sl, and activity
data_clean <- data_cleaning[-c(1,2,5,7,9)]
```

```{r}
# Check spelling in species and treatment but also generate a summary table
# There should be 6 different species. If no entries are misspelled, there should be 6 levels for species
str(data_clean)
```
```{r, writeCleaned, eval = TRUE, echo=TRUE}
#Im repeating this block down here because this is where it probably should be

path <- "./output/data/OA_activitydat_20190302_BIOL3207_output.csv"

write_csv(data, file = path)

```


### Table for the control group
```{r}
# Create a temporary tibble which contains data_clean, as well as the means and standard deviations for each species
means_temp <- data_clean %>% filter(treatment == "control") %>% group_by(species) %>%  mutate(meansl = mean(sl)) %>%  mutate(meanact = mean(activity)) %>%  mutate(sdsl = sd(sl)) %>% mutate(sdact = sd(activity))

# takes only the unique values from means_temp, and creates a new tibble with them. 
# Then arranges this new tibble in alphabetical order according to species, and adds a new column containing the number of observations for each species. The output of the count function is in alphabetical order and only has 6 rows, so this needed to be done here and not above.
# Then calculates the standard errors and adds new columns for them.
means.control <- tibble(Species = unique(means_temp$species), Mean.Standard.Length = unique(means_temp$meansl), Mean.Activity = unique(means_temp$meanact), sdsl = unique(means_temp$sdsl), sdact = unique(means_temp$sdact)) %>% arrange(Species) %>% cbind(count(means_temp, species)[,2]) %>% mutate(SE.Standard.Length = sdsl/n) %>% mutate(SE.Activity = sdact/n)
```


```{r}
# Use flextable to render the summary table in a tidy format
flextable(means.control[,c(1,6,2,3,7,8)]) %>% set_header_labels(n = "Count")

```
### Table for the CO2 group
```{r}
# Create a temporary tibble which contains data_clean, as well as the means and standard deviations for each species
means_temp <- data_clean %>% filter(treatment == "CO2") %>% group_by(species) %>%  mutate(meansl = mean(sl)) %>%  mutate(meanact = mean(activity)) %>%  mutate(sdsl = sd(sl)) %>% mutate(sdact = sd(activity))

# takes only the unique values from means_temp, and creates a new tibble with them. 
# Then arranges this new tibble in alphabetical order according to species, and adds a new column containing the number of observations for each species. The output of the count function is in alphabetical order and only has 6 rows, so this needed to be done here and not above.
# Then calculates the standard errors and adds new columns for them.
means.CO2 <- tibble(Species = unique(means_temp$species), Mean.Standard.Length = unique(means_temp$meansl), Mean.Activity = unique(means_temp$meanact), sdsl = unique(means_temp$sdsl), sdact = unique(means_temp$sdact)) %>% arrange(Species) %>% cbind(count(means_temp, species)[,2]) %>% mutate(SE.Standard.Length = sdsl/n) %>% mutate(SE.Activity = sdact/n)
```


```{r}
# Use flextable to render the summary table in a tidy format
flextable(means.CO2[,c(1,6,2,3,7,8)]) %>% set_header_labels(n = "Count")

```


**STOP**: Before moving on, it's a good time to establish some good *GitHub* practices. You have just done an important step. It's time to save this file, stage it and commit it so that you have a record. Push these changes up using *GitHub Desktop*. It's important to do this frequently. It's probably not needed after every line of code, but it's good to do this when you have completed an important coding step. Of course, there's no harm in doing it more often. It will provide fine-scale tracking for you!

>**Question 5**: The new version of your Rmarkdown file should now be up on *GitHub*. In the browser window click on your most recent commit. Have a look at the file versioning system. You will notice two files side-by-side. Describe what you notice is being presented online. What do the red and green highlights mean?

```{r answer5, echo=TRUE, eval=FALSE}
## The old version of a file is presented on the left-hand-side, and the new version on the right. Red lines in the old file indicate lines which have been changed in the new version, and green lines on the right indicate lines which have been added or changed in the new version.
```

# **Task 5**

Ignoring figures can be important because they take up quite a lot of space in your *GitHub* repo. For example, huge data files, or figures (e.g., png) can take up a tonne of space. We also might not need to save and track these because we can recreate them with our own code or re-download, process, save and track what we need. 

`.gitignore` files are used to control what *Git* tracks and what it ignores. You should have created a new folder path: `output/figures/`. Write some code now to create a pretty figure using ggplot that shows the difference between control and acidification treatments for each of the fish species in the data set:

```{r, prettyfig, fig.align='center', fig.cap="figure 1"}
# ggplot figure showing mean activity for each treatment (Control, OA) for each species.
ggplot(data_clean, aes(activity, sl, color=treatment)) + geom_boxplot() + facet_wrap(~species)

```
```{r eval=F}
# Use ggsave to save the figure
ggsave('./output/figures/control.acid.species.png', width = 6, height = 4)
```



**Stretch Task**: The Clark et al. 2020 paper plots some pretty pictures on their figures. You have access to a folder called "pics/". Add the pics of the difference species from the "pics/" folder to your new plot. Explore the function `annotation_raster()` which might help you achieve this goal.

Note the code chunk used to make the figure. It has a `fig.cap` argument. That means Rmarkdown knows it's a figure and it will allow you to create a figure reference call. In other words, we can refer to our Figure \@ref(fig:prettyfig) by referring to the label for the chunk. This will automatically make a legend for us too (assuming you add one in). The same concept applied to Tables but the legend goes above these.

Now that you have the figure you may also want to write / save it as a separate file. Use `ggsave` function to save the figure(s) to your new `output/figures/`:

```{r, loadImages}
acantho <- readPNG("./pics/acantho.png")
ambon <- readPNG("./pics/ambon.png")
chromis <- readPNG("./pics/chromis.png")
humbug <- readPNG("./pics/humbug.png")
lemon <- readPNG("./pics/lemon.png")
whitedams <- readPNG("./pics/whitedams.png")
```

```{r, savefig}
data_clean %>% filter(species == "chromis"|species== "lemon"|species == "humbug") %>% ggplot(aes(species, activity, fill=treatment)) + geom_boxplot() + 
  annotation_raster(chromis, xmin = 0.7, xmax = 1.2,ymin = 72, ymax = 80) + ylim(15,80) + 
  annotation_raster(humbug, xmin = 1.7, xmax = 2.2,ymin = 72, ymax = 80) + ylim(15,80) + 
  annotation_raster(lemon, xmin = 2.7, xmax = 3.2,ymin = 72, ymax = 80) + ylim(15,80)
```
```{r eval=F}
# Use ggsave to save the figure
ggsave('./output/figures/species.activity.boxplot.png', width = 6, height = 4)
```


>**Question 6**: Given that you have added `output/figures/` to your `.gitignore` file describe what you notice about what you see in *GitHub Desktop*. 

```{r}
## This folder is not included in the repository at all, as it is seen as empty. By including another .gitignore file in the folder, the folders can be included (as they are necessary for the code to run) without including their contents.
```

Last question for this task. I promise! It's important to think very carefully about what you track and ignore.

>**Question 7**: Assume that you added the `pics/` folder to your working directory to plot pictures of each fish on your figure. Do you want to track the files in the pic/ folder on GitHub despite them being .png files? Explain your reasoning. 

```{r, answer6}
# The pics folder does need to be tracked on Github. We dont track the figures folder because the figures can be recreated by the code in the r markdown document, but this is not true for the pictures. Much like with the raw data, the code needs existing pictures to be supplied to it.
```

# **Task 6**
This task involves teaming up with a collaborator. Exchange *GitHub* username details and add each other to your repo. Clone each others' repo on to your computer. Re-run their code. Does it work? If not, correct it for them. Explain to them WHY it didn't work. After all, they are right beside you! Think carefully about this. Will it still run on their computer if you have corrected it in a certain way?

Now, lets create a new figure in the code block below that simplifies the one produced in **Task 5**. Instead of all species, lets just plot three of the species (chromis, lemon, and acantho). In the figure code chunk make sure you add the necessary arguments (e.g., `fig.cap`) so that you can refer to Figure \@ref(fig:collabFig).

```{r, collabFig, echo=TRUE, eval=TRUE}
# You want to make changes to your collaborators figure in Task 5. Maybe you want to create a figure that focuses only on three fish species instead of the 5. More specifically, chromis, lemon, and acantho. Add code here to revise their figure to do that.
data3 <- data_clean%>% filter(species == "chromis"|species== "lemon"|species == "acantho")
ggplot(data = data3, aes(x=treatment,y =activity,fill =species))+geom_boxplot()
```


# **Task 7**
This task involves creating and resolving conflicts. Conflicts in files are denoted with specific markers. They look like this when you open a file with conflicts.

 <<<<<<<<< HEAD
  
  THIS IS YOUR CODE
  
 ==============
  
  THIS IS YOUR PARTNERS CODE
  
 !>>>>>>>>928731027301723

Resolving is easy. Decide on what changes you think are the best to proceed with and remove conflict markers. 

>**Stretch Task**: Try creating another conflict in the `collabFig` code chunk of the Rmarkdown file. Resolve the conflict again. More practice doing this is always good!

Once you have figured out how to create and solve conflicts it's time to update the README file with a little more detail about your project and the general workflow. The *GitHub* webpage uses the README file as a sort of introduction to the project. 

**Task**: Provide details about the workflow (i.e., which files are used, when and why) and write a detailed description of the data file used. Include the details about what the column means and which data file someone should use. 

Think about what you would need to know to make sure you can replicate a study. Provide these details so they are easy to find on the README.

# **Task 8**
There's not too much to do in this task on the coding front! You just need to create a *GitHub* issue and create a 'To Do' list on *GitHub* for you and your collaborator. 

# **Task 9**
Here, run some statistical tests to determine, for each species, whether the control vs high $CO^2$ treatments differ significantly from each other and in what direction. Provide the difference in means, their 95% confidence intervals, t-statistic, df and p-value. 

>**Stretch Task**: You can of course do this for each species seperately, but those who want a challenge, think about how you might use a loop or even some wrangling methods you have already learnt from the tidyverse to run these tests across all 6 species in a single block of code. If you're familiar with functions, you can even think about writing your own function! All these strategies will avoid having to copy and paste large chunks of code. If you're repeating anything, writing functions and loops are good ways to simplify.

```{r, stats, echo=TRUE, eval=TRUE}
#first we'll compile the data to make a table about the activity in control vs treatment groups
#make results object
results_activity <- tibble(Species = c(1:6),
  Diff.in.mean = c(1:6),
  T.stat = c(1:6),
  P.stat = c(1:6),
  Conf.Int = c(1:6),
  df = c(1:6))

#loop 6 times because we have six species
for(i in 1:6){
  #filter data by ith level of the species factor
  temp_data <- filter(data_clean, species == levels(data_clean$species)[i])

  #run stat test with subset
  temp_test <- t.test(temp_data$activity[temp_data$treatment == "CO2"],temp_data$activity[temp_data$treatment == "control"],var.equal=T)
  
  #extract only the information we need and store relevant values in results object
  #the species name, stored in the first column
  results_activity$Species[i] <- levels(data_clean$species)[i]
  #the difference in means, stored in the second column
  results_activity$Diff.in.mean[i] <- abs(unname(temp_test$estimate)[1]-unname(temp_test$estimate)[2])
  #the t statistic, stored in the third column
  results_activity$T.stat[i] <- unname(temp_test$statistic)
  #the p-value, stored in the fourth column
  results_activity$P.stat[i] <- temp_test$p.value
  #the confidence interval, stored in the fifth column
  #These are being put in one column because its only ever going to be used for displaying the interval in a table
  results_activity$Conf.Int[i] <- paste(signif(temp_test$conf.int[1],2), signif(temp_test$conf.int[2],2), sep=", ")
  #The degrees of freedom, stored in the sixth column
  results_activity$df[i] <- unname(temp_test$parameter)
}

#next we'll do the same as above, but for length instead of activity
#make results object
results_sl <- tibble(Species = c(1:6),
  Diff.in.mean = c(1:6),
  T.stat = c(1:6),
  P.stat = c(1:6),
  Conf.Int = c(1:6),
  df = c(1:6))

#loop 6 times because we have six species
for(i in 1:6){
  #filter data by ith level of the species factor
  temp_data <- filter(data_clean, species == levels(data_clean$species)[i])

  #run stat test with subset
  temp_test <- t.test(temp_data$sl[temp_data$treatment == "CO2"],temp_data$sl[temp_data$treatment == "control"],var.equal=T)
  
  #extract only the information we need and store relevant values in results object
  #the species name, stored in the first column
  results_sl$Species[i] <- levels(data_clean$species)[i]
  #the difference in means, stored in the second column
  results_sl$Diff.in.mean[i] <- abs(unname(temp_test$estimate)[1]-unname(temp_test$estimate)[2])
  #the t statistic, stored in the third column
  results_sl$T.stat[i] <- unname(temp_test$statistic)
  #the p-value, stored in the fourth column
  results_sl$P.stat[i] <- temp_test$p.value
  #the confidence interval, stored in the fifth column
  #These are being put in one column because its only ever going to be used for displaying the interval in a table
  results_sl$Conf.Int[i] <- paste(signif(temp_test$conf.int[1],2), signif(temp_test$conf.int[2],2), sep=", ")
  #The degrees of freedom, stored in the sixth column
  results_sl$df[i] <- unname(temp_test$parameter)
}

```

```{r, table1, echo=TRUE, eval=TRUE, tab.cap = "table1"}
# Using the resulting object created above, which should be a table with all the summary statistics, t, df and p-value for each species create a table. Note that there is a tab.cap argument in the chunk arguments. Write a caption here. 
## these are different from what was asked for above. So which are we using?
flextable(results_activity)
```
```{r, table2, echo=TRUE, eval=TRUE, tab.cap = "table2"}
# Using the resulting object created above, which should be a table with all the summary statistics, t, df and p-value for each species create a table. Note that there is a tab.cap argument in the chunk arguments. Write a caption here. 
## these are different from what was asked for above. So which are we using?
flextable(results_sl)
```

Now that you have a table, you can reference it within a document. For example, you can make a call to Table \@ref(tab:table1) by referring to the name of the code chunk. When you knit the html it will create a hyperlink to your table and insert a legend above the table for you. How cool is that!?

> **Question 8**: Pick one of your favorite species and write about the results to a reader. Write in the Rmarkdown file below what 1) the means and mean differences between control and acidification treatment is along with 2) the 95% confidence intervals of the difference

You can write your blurb below this. Before you do that, a few cool features of Rmarkdown. You can actually code in objects so that, when they are rendered they replace the inline code chunk with the result. To give you an example, an inline code chunk is written as follows: `r "add code here"`. When you render the document, whatever you place in the "add code here" section will be rendered. In this case, we are giving a string, so it simply just adds that in the place where the code is, render and see for yourself.  

Moving forward on that you can also add in an object and whatever that objects value is will also be spit out. For example, consider the following: `r x = 10; x`. What will happen? Well, it will place in the value 10 when rendered. Again, if you don't believe me, check for yourself by rendering the document. 

This is all **VERY** cool because that means if your code or data change than you can update your entire report very fast. It's also 100% reproducible. We know exactly where every single value in your report comes from. This is all pretty helpful when you want to check your code and report side-by-side. Now that you have a bit more detail fill in the following:

Mean activity for `r x=means.control$Species[1]; x` in the control group was `r x=means.control$Mean.Activity[1]; x` (s / min) compared to the OA treatment group, which was `r x = means.CO2$Mean.Activity[1]; x ` (s / min). The difference between control and OA treatment means was `r x=results_activity$Diff.in.mean[1]; x` (s / min) (95% CI: `r x=results_activity$Conf.Int[1]; x`). 

Note the difference in means is not actually outside the confidence interval, R is just doing some weird and unasked-for rounding.

Now, using what you just learnt, describe what the null hypothesis being tested was and provide statistical evidence (t-statistic, df, and p-value) to support your conclusion about whether we can reject the null hypothesis. Again, make sure you use in-line code. Write you answer below:

**Write your answer here**
The null hypothesis being tested would be that there is no difference in activity level between the control group and the treatment group, for the species `r x=means.control$Species[1]; x`.
The p-value calculated was `r x=results_activity$P.stat[1]; x`, with a t-statistic of `r x=results_activity$T.stat[1]; x` and `r x=results_activity$df[1]; x` degrees of freedom. Thus, the null hypothesis cannot be rejected.

Re-analyse the data for a single species using permutations instead of a t-test. Do your results differ?


```{r}
#permutation analysis for the "acantho" species activity

#create an empty tibble to contain the permutation results
#the 'stat' column will hold the t-statistic for the permutation
#the 'extreme' column will record whether this t-stat is greater than the true data's t-stat
samp_dist <- tibble(stat = rep(F,5000), extreme = rep(F,5000))

for(i in 1:5000){
  #create a temporary data set in which the treatment column is shuffled, and keep only the data for "acantho" species
  temp_data <- data_clean %>% mutate(treatment = sample(treatment, length(treatment), replace = F)) %>% filter(species == "acantho")
  #run a t-test on this permutation, and save the t-statistic in the samp_dist object
  samp_dist$stat[i] <- t.test(temp_data$activity[temp_data$treatment == "CO2"],temp_data$activity[temp_data$treatment == "control"],var.equal=T)$statistic
  #record whether this permutation's t-stat is greater than the data's t-stat
  samp_dist$extreme[i] <- (abs(samp_dist$stat[i]) > abs(results_activity$T.stat[1]))
}

#this proportion is our p-value for the permutation analysis
p <- length(which(samp_dist$extreme)) / length(which(!samp_dist$extreme))
p
```
The p-value from the permutation analysis, `r p=p; p`, is higher than from the t-test. However, both are too high to reject the null hypothesis regardless.

>**Stretch Task**:  If you really want a challenge try doing permutation tests for each species. Again, loops, functions or tidyverse (or even combinations might help). 

```{r, stretch2, echo=TRUE, eval=FALSE}
# Add your code here.
```

Below. Add a few sentences for the species (or multiple species) you talked about above to describe the permutation results:

**Add your text and inline code chunks here**

# **Task 10**

This is a stretch task on the use of *GitHub* and the challenges (or maybe lack of challenges) of reproducing others' work. If you finish the above tasks, then, have a crack at this one. See the html for details.
